# This YAML file provides information about each criterion.
# The top level key is the major (top-level) group key,
# within that is the minor (secondary) group key,
# and within each minor group is a set of criteria identifiers.
# With each criterion identifiers the following keys may be inside:
#   category: MUST|SHOULD|SUGGESTED # required
#   future: true|false # optional, default false
#   na_allowed: true|false # optional, default false
#   na_justification_required: true|false # optional, default false
#   met_justification_required: true|false # optional, default false
#   met_url_required: true|false # optional, default false
#   description: ...HTML description... # required
#   details: ...HTML description... # optional
#   met_placeholder: ...special met_placeholder text... # optional
#   unmet_placeholder: ...special unmet_placeholder text... # optional
#   na_placeholder: ...special na_placeholder text... # optional
#   met_suppress: true|false # optional, default false. Suppress justification?
#   unmet_suppress: true|false # optional, default false. Suppress just.
#   rationale: ...text describing the rationale for this criterion.
#   autofill: ...text describing *ideas* for how to autofill, in markdown
#
# Please note that autofill text is *not* a guarantee of how it will
# be implemented (or even if it will be automated); it is simply a way
# to record ideas that might be implemented.  Also, autofill is often
# used to *guess* correct values, to help speed filling in the form;
# we only force values if we are confident in their answer or are willing
# to require that the information be provided in a specific way.
# We've focused on GitHub, but where reasonable we'd like to create
# portability layers and support other forges like SourceForge,
# Savannah, Bitbucket, and GitLab; we'd also like to be able to support
# standalone sites (e.g., detect use of Bugzilla and work with that).
#
# We use an *ordered* map (omap), because the order below is used to determine
# the order of presentation.  In Ruby this doesn't really matter because
# (current) Ruby hashes are ordered anyway. We use !!omap so that
# any other tool reading this format will know to preserve the order.
--- !!omap
- Basics: !!omap
  - Basic Project Website Content: !!omap
    - description_good:
        category: MUST
        description: >
          The project website MUST succinctly describe what the software does
          (what problem does it solve?).
        details: >
          This MUST be in language that potential users can understand
          (e.g., it uses minimal jargon).
        met_placeholder: >
          (Optional) Where is the succinct description?  Consider
          providing a URL.
        autofill: >
          We could try examining the project website or README for an
          early sentence of the form (This software|project name).
          It's unclear how effective this would be; we could survey a number
          of existing projects to see if there are common patterns.
    - interact:
        category: MUST
        description: >
          The project website MUST provide information on how to:
          obtain, provide feedback (as bug reports or enhancements),
          and contribute to the software.
        met_placeholder: >
          (Optional) Where is this information?  Consider providing URL(s).
        autofill: >
          Look on the project website for words like "download|obtain",
          "contribute|bug report|feedback|enhancement", and
          "contribute|pull request|merge request".
    - contribution:
        category: MUST
        met_url_required: true
        description: >
          The information on how to contribute MUST explain the
          contribution process (e.g., are pull requests used?)
        details: >
          We presume that
          <a href="https://guides.github.com/activities/contributing-to-open-source/">projects on GitHub use issues and pull requests</a>
          unless otherwise noted.
          This information can be short, e.g., stating that the project uses
          pull requests, an issue tracker, or posts to a mailing list
          (which one?)
        met_placeholder: >
          (URL required) What is the process? What URL explains it?
        autofill: >
          Look on the project website for words like
          "contribute|bug report|feedback|enhancement" and
          "contribute|pull request|merge request".
        rationale: >
          Contributors need to understand not only how to contribute,
          but also the overall contribution process, so that they'll
          understand how their work could be incorporated and what
          the expectations are after the initial submission.
          This means that wherever the project describes how to contribute,
          the project must include (directly or by reference) information
          on the contribution process.  Note that criterion "interact"
          (listed earlier) requires that the contribution information
          be on the project website.
    - contribution_requirements:
        category: SHOULD
        met_url_required: true
        description: >
          The information on how to contribute SHOULD include the
          requirements for acceptable contributions
          (e.g., a reference to any required coding standard).
        unmet_placeholder: >
          Why are the requirements so obvious that this information
          isn't needed?
        autofill: >
          Look for a CONTRIBUTING{,.md,.txt,.html} file.
  - OSS License: !!omap
    - floss_license:
        category: MUST
        description: >
          The software produced by the project MUST be released as FLOSS.
        details: >
          FLOSS is software released in a way that meets the
          <a href="https://opensource.org/osd-annotated">Open Source Definition</a>
          or
          <a href="http://www.gnu.org/philosophy/free-sw.en.html">Free Software
          Definition</a>.
          Examples of such licenses include the
          <a href="http://creativecommons.org/publicdomain/zero/1.0/">CC0</a>,
          <a href="https://opensource.org/licenses/MIT">MIT</a>, <a
          href="https://opensource.org/licenses/BSD-2-Clause">BSD 2-clause</a>,
          <a href="https://opensource.org/licenses/BSD-3-Clause">BSD
          3-clause revised</a>, <a
          href="https://opensource.org/licenses/Apache-2.0">Apache 2.0</a>,
          <a href="https://opensource.org/licenses/lgpl-license">Lesser
          GNU General Public License (LGPL)</a>, and the <a
          href="https://opensource.org/licenses/gpl-license">GNU General Public
          License (GPL)</a>.
          For our purposes, this means that the license MUST be: <ul>
          <li><a href="https://opensource.org/licenses">an approved license
          by the Open Source Initiative (OSI)</a>, or</li>
          <li><a href="https://www.gnu.org/licenses/license-list.html">a free
          license as approved by the Free Software Foundation (FSF)</a>, or</li>
          <li><a href="https://www.debian.org/legal/licenses/">a free license
          acceptable to Debian main</a>, or</li>
          <li><a
          href="https://fedoraproject.org/wiki/Licensing:Main?rd=Licensing">a
          "good" license according to Fedora</a>.</li>
          </ul>
          The software MAY also be licensed other ways
          (e.g., "GPLv2 or proprietary" is acceptable).
        rationale: >
          These criteria are designed for FLOSS projects,
          so we need to ensure that they're only used where they apply.
          Some projects may be mistakenly considered FLOSS even though they
          are not (e.g., they might not have any license, in which case the
          defaults of the country's legal system apply, or they might use a
          non-FLOSS license).
          We've added "produced by the project" as a clarification -
          many projects use non-FLOSS software/services in the process of
          creating software, or depend on them to run,
          and that is allowed.
        autofill: >
          We currently use GitHub's API to request license information.
          This API examines the LICENSE file using the gem licensee.
          This only works on GitHub, and only in simple cases
          (when there's a single license).
          We could in addition look for the file LICENSE.spdx for the
          entry 'PackageLicenseDeclared' - these aren't included often,
          but it would let people declare *exactly* what license is in use.
          We could add running Ben Balter's gem
          [licensee](https://github.com/benbalter/licensee), this is the same
          library used by GitHub but we can then apply it outside of GitHub.
          [Licensee issue #85](https://github.com/benbalter/licensee/issues/85)
          proposes adding LICENSE.spdx support to licensee.
          See [&#8220;Open Source Licensing by the Numbers&#8221; by Ben Balter](https://speakerdeck.com/benbalter/open-source-licensing-by-the-numbers).
          We could also do more specialized analysis (e.g., looking for
          license information in various packaging formats) - this would
          probably be best done by improving some existing library
          like licensee.
    - floss_license_osi:
        category: SUGGESTED
        description: >
          It is SUGGESTED that any required license(s)
          for the software produced by the project be
          <a href="https://opensource.org/licenses">approved by the
          Open Source Initiative (OSI).</a>
        details: >
          The OSI uses a rigorous approval process to determine
          which licenses are OSS.
        met_suppress: true
        rationale: >
          Unusual licenses can cause long-term problems
          for FLOSS projects and are more difficult for tools to handle.
          That said, there are FLOSS licenses that are not OSI-approved,
          e.g., the CC0 license is used by many projects but is not
          OSI-approved at the time of this writing.
          We expect that more advanced badges would set a higher bar (e.g.,
          that it <em>must</em> be released under an OSI-approved license).
        autofill: >
          Currently we compare the license to see if it's on a simple list
          from OSI.  We could add support for automatically getting the list
          from elsewhere (e.g., OSI or SPDX), and support more complex
          license structures (OR, AND, and WITH).
    - license_location:
        category: MUST
        met_url_required: true
        description: >
          The project MUST post the license(s) of its results
          in a standard location in their source repository.
        details: >
          E.g., as a top-level file named LICENSE or COPYING.
          License filenames MAY be followed by an extension
          such as ".txt" or ".md".
        rationale: >
          The goal is to make the license very clear and connected with
          the project results it applies to.  It is a good idea to also
          make the license clear on the project website, but there isn't
          a widely-accepted way to do that today.
        autofill: >
          Look for files with the name LICENSE, COPYING, or COPYING-(name)
          optionally extensions .txt or .md.  Name could include
          GPL, LGPL, and MIT.
  - Documentation: !!omap
    - documentation_basics:
        category: MUST
        description: >
          The project MUST provide basic documentation for the software.
        details: >
          This documentation must be in some media (such as text or video)
          that includes:
          how to install it, how to start it, how to use it (possibly with a
          tutorial using examples), and how to use it securely (e.g., what to do
          and what not to do) if that is an appropriate topic for the software.
          The security documentation need not be long.
          The project MAY use hypertext links to
          non-project material as documentation.
        met_placeholder: >
          (Optional) What URL(s) are the starting points to for documentation?
        rationale: >
          Potential users need documentation so that they can learn how to
          use the software.
          This documentation could be provided
          via the project website or repository, or even
          via hyperlink to some external information, so we do not specify
          exactly where this information is.
        autofill: >
          Look for the project web page,
          or a direct links from it on the same site,
          that includes words like "install(ation)?", "use|using",
          and "security|secure".
    - documentation_interface:
        category: MUST
        description: >
          The project MUST provide reference documentation that describes
          its external interface (both input and output).
        details: >
          The project MAY use hypertext links to non-project material
          as documentation.
          Documentation MAY be automatically generated
          (where practical this is often the best way to do so).
          Documentation of a REST interface may be generated using
          Swagger/OpenAPI.
          Code interface documentation MAY be generated using
          tools such as <a href="http://usejsdoc.org/">JSDoc</a>
          (JavaScript), <a href="https://esdoc.org/">ESDoc</a> (JavaScript),
          pydoc (Python), and Doxygen (many).  Merely having comments in
          implementation code is not sufficient to satisfy this criterion;
          there needs to be an easy way to see the information without
          reading through all the source code.
        autofill: >
          Look for a "docs" or "doc" directory, or the main site, with
          .txt, .html, .md, .tex extension and uses the word "interface".
  - Other: !!omap
    - sites_https:
        category: MUST
        description: >
          The project sites (website, repository, and download URLs)
          MUST support HTTPS using TLS.
        details: >
          You can get free certificates from
          <a href="https://letsencrypt.org/">Let's Encrypt</a>.
          Projects MAY implement this criterion using (for example) <a
          href="https://help.github.com/articles/securing-your-github-pages-site-with-https/">GitHub
          pages</a>, <a
          href="https://about.gitlab.com/2016/12/24/were-bringing-gitlab-pages-to-community-edition/">GitLab
          pages</a>, or <a
          href="https://sourceforge.net/blog/introducing-https-for-project-websites/">SourceForge
          project pages</a>.  If you are using GitHub pages with
          custom domains, you MAY use a content delivery network
          (CDN) as a proxy to support HTTPS, such as described in the <a
          href="https://blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare/">blog
          post "Secure and fast GitHub Pages with CloudFlare"</a>,
          to satisfy this criterion. If you support HTTP,
          we urge you to redirect the HTTP traffic to HTTPS.
        autofill: >
          Look at project, repo, and download URLs. https is okay, http is not.
          Typically anything supporting HTTPS also supports TLS, so
          it's probably not worth trying to detect that specifically.
    - discussion:
        category: MUST
        description: >
          The project MUST have one or more mechanisms
          for discussion (including proposed changes and issues) that are
          searchable, allow messages and topics to be addressed by URL,
          enable new people to participate in some of the discussions, and
          do not require client-side installation of proprietary software.
        details: >
          Examples of acceptable mechanisms include
          archived mailing list(s),
          GitHub issue and pull request discussions, Bugzilla, Mantis, and Trac.
          Asynchronous discussion mechanisms (like IRC) are acceptable if
          they meet these criteria; make sure there is a URL-addressable
          archiving mechanism.
          Proprietary JavaScript, while discouraged, is permitted.
        autofill: >
          Currently if it's on GitHub we assume they will use its mechanisms.
          We could do the same for other forges like
          SourceForge, GitLab, and Savannah.
          We could also look for links from the project website that suggest
          the use of Bugzilla, Mantis, or Trac.
    - english:
        category: SHOULD
        description: >
          The project SHOULD provide documentation in English and be able
          to accept bug reports and comments about code in English.
        details: >
          English is currently the <a
          href="https://en.wikipedia.org/wiki/Lingua_franca">lingua franca</a>
          of computer technology; supporting English increases the number
          of different potential developers and reviewers worldwide.
          A project can meet this criterion even if its core developers'
          primary language is not English.
        autofill: >
          Look at project and/or repo page.  If it's in English,
          then clearly the project can accept English.
          We can use more general tools to detect the natural language,
          or simple mechanisms like using dictionaries/spellcheckers to
          see if it's mostly English.
- 'Change Control': !!omap
  - Public version-controlled source repository: !!omap
    - repo_public:
        category: MUST
        description: >
          The project MUST have a version-controlled source repository that
          is publicly readable and has a URL.
        details: >
          The URL MAY be the same as the project URL.
          The project MAY use private (non-public) branches in specific
          cases while the change is not publicly released (e.g., for fixing
          a vulnerability before it is revealed to the public).
        autofill: >
          We currently assume that being on GitHub is enough.
          Again, consider supporting other forges.
    - repo_track:
        category: MUST
        description: >
          The project's source repository MUST track
          what changes were made, who made
          the changes, and when the changes were made.
        autofill: >
          If it uses git, subversion (svn), mercurial (hg), or even CVS
          this would normally be met.
    - repo_interim:
        category: MUST
        description: >
          To enable collaborative review, the project's source repository MUST
          include interim versions for review between releases;
          it MUST NOT include only final releases.
        details: >
          Projects MAY choose to omit specific interim versions
          from their public source repositories
          (e.g., ones that fix specific non-public security vulnerabilities,
          may never be publicly released, or include material that cannot
          be legally posted and are not in the final release).
        autofill: >
          Consider checking if there are many versions.  If versions are
          only posted once every 3+ months, there's probably a problem.
    - repo_distributed:
        category: SUGGESTED
        description: >
          It is SUGGESTED that common distributed version control software
          be used (e.g., git) for the project's source repository.
        details: >
          Git is not specifically required and projects
          can use centralized version control software
          (such as subversion) with justification.
        autofill: >
          Look for git, subversion (svn), and mercurial (hg).
  - Unique version numbering: !!omap
    - version_unique:
        category: MUST
        description: >
          The project results MUST have a unique version identifier for each
          release intended to be used by users.
        details: >
          This MAY be met in a variety of ways including
          a commit IDs (such as git commit id or mercurial changeset id)
          or a version number (including version numbers that use
          semantic versioning or date-based schemes like YYYYMMDD).
        autofill: >
          Look for downloads with version numbers in the filename, or
          version tags in a git repo.
    - version_semver:
        category: SUGGESTED
        description: >
          It is SUGGESTED that the
          <a href="http://semver.org">Semantic Versioning (SemVer) format</a>
          be used for releases.
        details: >
          Other version numbering schemes, such as commit IDs (such as
          git commit id or mercurial changeset id)
          or date-based schemes like YYYYMMDD, MAY be used as
          version numbers, since they are unique.
          Some alternatives can cause problems, because
          users may not be able to easily determine if they are up-to-date.
          SemVer may be less helpful for identifying software releases
          if all recipients only run the latest version
          (e.g., it is the code for a single website or internet service that
          is constantly updated via continuous delivery).
        rationale: >
          SemVer is widely used to communicate what an update
          is (e.g., if it involves incompatible API changes),
          whether something is newer or older.  The scheme is simple,
          supports multiple simultaneous branches, and because it uses at
          least three numbers it can be distinguished from floating point.
          However, many find SemVer less useful for identifying software
          versions if only one version of the component is run (e.g.,
          it is the code for a single website or internet service that
          is constantly updated via continuous delivery).
          For more discussion of the pros and cons of SemVer, see
          <a href="https://news.ycombinator.com/item?id=13378637">Hacker News' Is Semantic Versioning an Anti-Pattern?</a> and
          <a href="https://surfingthe.cloud/semantic-versioning-anti-pattern/">The Semantic Versioning Anti-Pattern</a>.
        met_suppress: true
        autofill: >
          Look for git tags (at least on GitHub) that have version format, e.g.,
          v?[0-9]+\.[0-9]+\.[0-9]+.*   The prefixed 'v' is
          sometimes used in tags.
    - version_tags:
        category: SUGGESTED
        description: >
          It is SUGGESTED that projects identify each release within their
          version control system.
          For example, it is SUGGESTED that those using git identify
          each release using git tags.
        autofill: >
          Again, look for git tags (at least on GitHub) that have
          version format, e.g., v?[0-9]+\.[0-9]+\.[0-9]+.*   The
          prefixed 'v' is sometimes used in tags.
  - Release notes: !!omap
    - release_notes:
        category: MUST
        met_url_required: true
        na_allowed: true
        na_justification_required: true
        description: >
          The project MUST provide, in each release, release notes that
          are a human-readable summary of major changes in that release
          to help users determine if they should upgrade and what the
          upgrade impact will be. The release notes MUST NOT be the raw
          output of a version control log (e.g., the "git log" command
          results are not release notes). Projects whose results are not
          intended for reuse in multiple locations (such as the software
          for a single website or service) AND employ continuous delivery
          MAY select "N/A".
        details: >
          The release notes MAY be implemented in a variety of ways.
          Many projects provide them in a file named "NEWS", "CHANGELOG",
          or "ChangeLog", optionally with extensions such as ".txt", ".md",
          or ".html".  Historically the term "change log" meant a log of
          <i>every</i> change, but to meet these criteria what is needed
          is a human-readable summary.  The release notes MAY instead be
          provided by version control system mechanisms such as the <a
          href="https://github.com/blog/1547-release-your-software">GitHub
          Releases workflow</a>.
        rationale: >
          Release notes are important because they help users decide whether
          or not they will want to update, and what the impact would be (e.g.,
          if the new release fixes vulnerabilities).  We realize this may not
          apply to projects whose main results are continuously updated and
          are deployed to primarily one place and so allow "N/A" from
          such projects.
        autofill: >
          Look for version-controlled files named NEWS, CHANGELOG, or ChangeLog
          (optionally with an extension .txt, .md, or .html).
          Also check to see if it uses a GitHub Releases workflow.
    - release_notes_vulns:
        category: MUST
        na_allowed: true
        na_justification_required: true
        description: >
          The release notes MUST identify every publicly known vulnerability
          that is fixed in each new release. This is "N/A" if there are no
          release notes or there have been no publicly known vulnerabilities.
        autofill: >
          Examine the release notes (per above) to see if they include
          CVE identifiers.  Also,
          use a vulnerability database such as the
          National Vulnerability Database (NVD) to try to identify
          publicly known vulnerabilities in this software, and see if all of
          them are mentioned in the release notes.
- Reporting: !!omap
  - Bug-reporting process: !!omap
    - report_process:
        category: MUST
        description: >
          The project MUST provide a process for users to submit bug reports
          (e.g., using an issue tracker or a mailing list).
        met_url_required: true
        autofill: >
          On GitHub we presume that at least issue trackers can be used.
          Search CONTRIBUTING (if it exists) for a phrase like "bug reports".
    - report_tracker:
        category: SHOULD
        description: >
          The project SHOULD use an issue tracker
          for tracking individual issues.
        unmet_placeholder: Why is there no issue tracker?
        autofill: >
          On GitHub we presume that at least issue trackers can be used.
          Search CONTRIBUTING (if it exists) for a phrase like "issue tracker".
    - report_responses:
        category: MUST
        description: >
          The project MUST acknowledge a majority of bug reports submitted in
          the last 2-12 months (inclusive); the response need not include a fix.
        autofill: >
          Examine issue tracker, and see what is marked as a "bug".
          Exclude the top contributor(s) as reported by the repo changes.
          Then examine the responses for the rest.
          Measuring "top contributors" is tricky; one potential rule is
          those who contribute more than 10% of the system, or, when you
          sort people by their contributions, the ones who cumulatively wrote
          2/3s of the system.  However,
          these measures may be difficult to obtain
          in a short time - perhaps just exclude anyone listed in AUTHORS or
          CREDITS, or someone listed in the last X commits?
    - enhancement_responses:
        category: SHOULD
        description: >
          The project SHOULD respond to a majority (&gt;50%)
          of enhancement requests in the last 2-12 months (inclusive).
        details: >
          The response MAY be 'no' or a discussion about its merits.
          The goal is simply that there be some response to some requests,
          which indicates that the project is still alive.
          For purposes of this criterion, projects need not count fake requests
          (e.g., from spammers or automated systems).
        autofill: >
          Examine issue tracker, and see what is marked as an "enhancement".
          Exclude the top contributor(s) as reported by the repo changes.
          Then examine the responses for the rest.
    - report_archive:
        category: MUST
        met_url_required: true
        description: >
          The project MUST have a publicly available archive for reports and
          responses for later searching.
        autofill: >
          If on GitHub, Savannah, SourceForge, GitLab, this is probably fine.
  - Vulnerability report process: !!omap
    - vulnerability_report_process:
        category: MUST
        met_url_required: true
        description: >
          The project MUST publish the process for reporting vulnerabilities
          on the project site.
        details: >
          E.g., a clearly designated mailing address on
          https://PROJECTSITE/security,
          often in the form security@example.org.
          This MAY be the same as its bug reporting process.
          Vulnerability reports MAY always be public, but
          many projects have a private vulnerability reporting mechanism.
        autofill: >
          Look for phrase like "vulnerability reporting" or
          "how to report vulnerabilities" in various documents
          like README, CONTRIBUTING, or a doc/* file.
    - vulnerability_report_private:
        category: MUST
        na_allowed: true
        met_url_required: true
        description: >
          If private vulnerability reports are supported, the project MUST
          include how to send the information in a way that is kept private.
        details: >
          Examples include a private defect report submitted on the web
          using HTTPS (TLS) or an email encrypted using OpenPGP.
          If vulnerability reports are always public (so there
          are never private vulnerability reports),
          choose "not applicable" (N/A).
        autofill: >
          Look for a phrase like "private vulnerability reporting" or
          "how to report private vulnerabilities" in various documents
          like README, CONTRIBUTING, or a doc/* file, and *also*
          look for an OpenPGP key to use for encrypting the information.
          Sadly, while Bugzilla easily supports this,
          GitHub doesn't currently support this in its issue tracker, see
          https://github.com/isaacs/github/issues/37
    - vulnerability_report_response:
        category: MUST
        na_allowed: true
        description: >
          The project's initial response time for any vulnerability report received
          in the last 6 months MUST be less than or equal to 14 days.
        details: >
          If there have been no vulnerabilities reported in the last 6 months,
          choose "not applicable" (N/A).
        autofill: >
          If GitHub is used, and the issue tracker has something marked
          "security" or "vulnerability", measure the appropriate times.
          GitHub doesn't support private reports, though, so a lot of people
          won't use this.
          If Bugzilla is used, grab the information publicly available and
          track this.
- Quality: !!omap
  - Working build system: !!omap
    - build:
        category: MUST
        na_allowed: true
        description: >
          If the software produced by the project requires building for use,
          the project MUST provide a working build system that can
          automatically rebuild the software from source code.
        details: >
          A build system determines what actions need to occur to rebuild the
          software (and in what order), and then performs those steps.
          For example, it can invoke a compiler to compile the source code.
          If an executable is created from source code, it must be possible
          to modify the project's source code and then generate
          an updated executable with those modifications.
          If the software produced by the project depends on external
          libraries, the build system does <i>not</i> need
          to build those external libraries.
          If there is no need to build anything to use the software after
          its source code is modified, select "not applicable" (N/A).
        rationale: >
          If a project needs to be built but there is no
          working build system, then potential co-developers will not be
          able to easily contribute and many security analysis tools will be
          ineffective.
          This is related to
          <a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/">Joel Test</a>
          point 2, "Can you make a build in one step?"
        autofill: >
          See build_common_tools.
    - build_common_tools:
        category: SUGGESTED
        na_allowed: true
        description: >
          It is SUGGESTED that common tools be used for building the software.
        details: >
          For example, Maven, Ant, cmake, the autotools, make, or rake.
        autofill: >
          Look for files that suggest the use of a common build systems, e.g.:
          the autotools (configure.ac, makefile.am),
          traditional make (Makefile, makefile),
          cmake, rake, ant, maven, etc.
          See http://www.dwheeler.com/essays/releasing-floss-software.html
    - build_floss_tools:
        category: SHOULD
        na_allowed: true
        description: The project SHOULD be buildable using only FLOSS tools.
        autofill: >
          If it's packaged in a Linux distribution repo that is FLOSS-only,
          then this is met.  That includes official Debian distribution
          (but not contrib or non-free) or Fedora's official distribution.
          If it's only source code file extensions that don't normally require
          building (.py, .rb, etc.), then it is likely NA.
          If the build_common_tools answers are themselves FLOSS, then this
          is more likely to *also* be true.  The only *real* way to check this
          is to install and build on a system that only has FLOSS, and we
          won't have the time to do that ourselves.
  - Automated test suite: !!omap
    - test:
        category: MUST
        description: >
          The project MUST use at least one automated test suite
          that is publicly released as FLOSS (this test suite may be
          maintained as a separate FLOSS project).
        details: >
          The project MAY use multiple automated test suites (e.g., one
          that runs quickly, vs. another that is more thorough but requires
          special equipment).
        rationale: >
          Automated test suites immediately help detect a
          variety of problems.  A large test suite can find more problems, but
          even a small test suite can detect problems and provide a framework
          to build on.
        autofill: >
          See test_invocation, and use its value here also.
    - test_invocation:
        category: SHOULD
        description: >
          A test suite SHOULD be invocable in a standard way for that language.
        details: >
          For example, "make check", "mvn test", or "rake test".
        autofill: >
          Look in the build scripts for a non-empty test command.
          E.g., look for a Makefile (including Makefile.am) with a non-empty
          "check" or "test" entry.  Similarly look for an entry for
          maven (mvn test) or rake (rake test).
    - test_most:
        category: SUGGESTED
        description: >
          It is SUGGESTED that the test suite cover most (or ideally all)
          the code branches, input fields, and functionality.
        autofill: >
          We could run a test suite with coverage enabled, but that would
          take far too long for our time budget.
          However, we *could* look for a Coveralls or Codecov badge
          (a link to a badge under <https://coveralls.io>) and pull in
          *that* data (since that would be the final result).
          Coveralls or Code prefer 90% or more statement coverage.
    - test_continuous_integration:
        category: SUGGESTED
        description: >
          It is SUGGESTED that the project implement continuous integration
          (where new or changed code is frequently integrated into a central
          code repository and automated tests are run on the result).
        rationale: >
          See
          <a href="http://martinfowler.com/articles/continuousIntegration.html">Martin Fowler</a>
          There has been some shift in the meaning of the term
          continuous integration. Historically the term continuous
          integration focused on the first part - the frequent
          integration - and not on its testing.  However, over time the
          emphasis has shifted to include the notion of running automated tests
          as soon as the code is integrated.  We realize that this
          can be difficult for some projects to apply, which is why it
          is only SUGGESTED at the passing level.
        autofill: >
          Look for a .travis.yml or circle.yml file.
          We also see if it has a badge from CircleCI or Travis.
          Extra points: We could ask Travis or CircleCI if it's enabled.
          We could look for evidence of pulls each of which are "relatively"
          small (instead of rare massive changes being the norm), though
          that by itself would give less confidence.
          Also, make this depend on the "test" or "test_invocation" criterion.
  - New functionality testing: !!omap
    - test_policy:
        category: MUST
        description: >
          The project MUST have a general policy (formal or not) that as major
          new functionality is added to the software produced by the project,
          tests of that functionality should
          be added to an automated test suite.
        details: >
          As long as a policy is in place, even by word of mouth,
          that says developers should add tests to the automated
          test suite for major new functionality, select "Met."
        autofill: >
          Look for text patterns hinting at this in README, CONTRIBUTING,
          or the doc/* directory.
          Also, make this depend on the "test" or "test_invocation" criterion.
    - tests_are_added:
        category: MUST
        description: >
          The project MUST have evidence that the
          <a href="#test_policy">test_policy</a> for adding tests
          has been adhered to in
          the most recent major changes to the software produced by the project.
        details: >
          Major functionality would typically be mentioned in the release notes.
          Perfection is not required, merely evidence
          that tests are typically being added in practice to the automated
          test suite when new major functionality is added to the
          software produced by the project.
        autofill: >
          Look for evidence that new tests are created.
          E.G., do at least some contributions include new tests
          (e.g., changes to contents in a directory whose full pathname
          contains the phrase "test").
    - tests_documented_added:
        category: SUGGESTED
        description: >
          It is SUGGESTED that this policy on adding tests
          (see <a href="#test_policy">test_policy</a>) be
          <i>documented</i> in the instructions for change proposals.
        details: >
          However, even an informal rule is acceptable as long as the tests
          are being added in practice.
        autofill: >
          Look in CONTRIBUTING and README.  See also test_policy.
  - Warning flags: !!omap
    - warnings:
        category: MUST
        na_allowed: true
        description: >
          The project MUST enable one or more compiler warning flags, a "safe"
          language mode, or use a separate "linter" tool to look
          for code quality
          errors or common simple mistakes, if there is at least
          one FLOSS tool that
          can implement this criterion in the selected language.
        details: >
          Examples of compiler warning flags include gcc/clang "-Wall".
          Examples of a "safe" language mode include JavaScript "use strict"
          and perl5's "use warnings".
          A separate "linter" tool is simply a tool that examines the
          source code to look for code quality errors or common simple mistakes.
          These are typically enabled within the source code or
          build instructions.
        autofill: >
          See the "details" - search the build script and source code for these.
    - warnings_fixed:
        category: MUST
        na_allowed: true
        description: >
          The project MUST address warnings.
        details: >
          These are the warnings identified by the implementation
          of the <a href="#warnings">warnings</a> criterion.
          The project should fix warnings or mark them in the source code
          as false positives.  Ideally there would be no warnings, but a project
          MAY accept some warnings (typically less than 1 warning per 100
          lines or less than 10 warnings).
        autofill: >
          The only good way to do this is to actually do a build.
          If it uses CircleCI we could look at that.
    - warnings_strict:
        category: SUGGESTED
        na_allowed: true
        description: >
          It is SUGGESTED that projects be maximally strict with warnings,
          but this is not always practical.
        autofill: >
          If we find "-Wall -Wextra" in the build that's pretty strict.
- Security: !!omap
  - Secure development knowledge: !!omap
    - know_secure_design:
        category: MUST
        description: >
          The project MUST have at least one primary developer who knows
          how to design secure software.
        details: >
          This requires understanding the following
          design principles, including the 8 principles from <a
          href="http://web.mit.edu/Saltzer/www/publications/protection/">Saltzer
          and Schroeder</a>:
          <ul>
          <li>economy of mechanism (keep the design as simple and small as
          practical, e.g., by adopting sweeping simplifications)
          <li>fail-safe defaults (access decisions should deny by default, and
          projects' installation should be secure by default)
          <li>complete mediation (every access that might be limited must be
          checked for authority and be non-bypassable)
          <li>open design (security mechanisms should not depend on attacker
          ignorance of its design, but instead on more easily protected
          and changed information like keys and passwords)
          <li>separation of privilege (ideally, access to important objects
          should depend on more than one condition, so that defeating
          one protection system won't enable complete access.
          E.G., multi-factor authentication, such as requiring both a password
          and a hardware token, is stronger than single-factor authentication)
          <li>least privilege (processes should operate with the least privilege
          necessary)
          <li>least common mechanism (the design should minimize the mechanisms
          common to more than one user and depended on by all users, e.g.,
          directories for temporary files)
          <li>psychological acceptability (the human interface must be designed
          for ease of use - designing for "least astonishment" can help)
          <li>limited attack surface (the attack surface - the
          set of the different
          points where an attacker can try to enter or extract data - should
          be limited)
          <li>input validation with whitelists
          (inputs should typically be checked
          to determine if they are valid before they are accepted;
          this validation
          should use whitelists (which only accept known-good values),
          not blacklists (which attempt to list known-bad values)).
          </ul>
          A "primary developer" in a project is anyone who is familiar with
          the project's code base, is comfortable making changes to it, and is
          acknowledged as such by most other participants in the project.
          A primary developer would typically make a number of contributions
          over the past year (via code, documentation, or answering questions).
          Developers would typically be considered primary developers if they
          initiated the project (and have not left the project more than three
          years ago), have the option of receiving information on a private
          vulnerability reporting channel (if there is one), can accept commits
          on behalf of the project, or perform final releases of the project
          software.
          If there is only one developer,
          that individual is the primary developer.
        autofill: >
          We could try to search the documentation for evidence of phrases
          that suggest security knowledge, such as the phrases listed above.
    - know_common_errors:
        category: MUST
        description: >
          At least one of the project's
          primary developers MUST know of common kinds of
          errors that lead to vulnerabilities in this kind of software,
          as well as at least one method to counter or mitigate each of them.
        details: >
          Examples (depending on the type of software)
          include SQL injection, OS injection, classic buffer overflow,
          cross-site scripting, missing authentication,
          and missing authorization.
          See the <a href="http://cwe.mitre.org/top25/">CWE/SANS top 25</a> or
          <a href="https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project">OWASP Top 10</a>
          for commonly used lists.
        autofill: >
          We could try to search the documentation for evidence of phrases
          that suggest security knowledge, such as the phrases for common
          types of vulnerabilities such as CWE/SANS top 25 or OWASP top 10.
          Simply mentioning those could also be an indicator.
  - Use basic good cryptographic practices: !!omap
    - crypto_published:
        category: MUST
        na_allowed: true
        description: >
          The software produced by the project MUST use, by default,
          only cryptographic protocols
          and algorithms that are publicly published and reviewed by experts
          (if cryptographic protocols and algorithms are used).
        details: >
          These cryptographic
          criteria do not always apply because some software has no
          need to directly use cryptographic capabilities.
        # autofill: TODO
    - crypto_call:
        category: SHOULD
        na_allowed: true
        description: >
          If the software produced by the project
          is an application or library, and its primary
          purpose is not to implement cryptography, then it SHOULD only call on
          software specifically designed to implement cryptographic functions;
          it SHOULD NOT re-implement its own.
        # autofill: TODO
    - crypto_floss:
        category: MUST
        na_allowed: true
        description: >
          All functionality in the software produced by the project
          that depends on cryptography MUST be implementable using FLOSS.
        details: >
          See the
          <a href="https://opensource.org/osr">Open Standards Requirement
          for Software by the Open Source Initiative</a>.
        rationale: >
          Software must interoperate with other software. If the
          functionality cannot be implemented with FLOSS, e.g., because
          of patents, then this can set a trap for others who depend on
          the software.
        # autofill: TODO
    - crypto_keylength:
        category: MUST
        na_allowed: true
        description: >
          The security mechanisms within the software produced by the project
          MUST use default keylengths that at least
          meet the NIST minimum requirements
          through the year 2030 (as stated in 2012).
          It MUST be possible to configure the software so that
          smaller keylengths are completely disabled.
        details: >
          These minimum bitlengths are: symmetric key 112,
          factoring modulus 2048, discrete logarithm key 224,
          discrete logarithmic group 2048, elliptic curve 224,
          and hash 224 (password hashing is not covered by this
          bitlength, more information on password hashing can be found in the
          <a href="#crypto_password_storage">crypto_password_storage</a>
          criterion).
          See <a href="http://www.keylength.com">http://www.keylength.com</a>
          for a comparison of keylength recommendations from
          various organizations.
          The software MAY allow smaller keylengths in some configurations
          (ideally it would not, since this allows downgrade attacks,
          but shorter keylengths are sometimes necessary for interoperability).
        # autofill: TODO
    - crypto_working:
        category: MUST
        na_allowed: true
        description: >
          The default security mechanisms within the software produced
          by the project MUST NOT depend on
          broken cryptographic algorithms (e.g., MD4, MD5, single DES,
          RC4, Dual_EC_DRBG) or use cipher modes that are inappropriate
          to the context (e.g., ECB mode is almost never appropriate
          because it reveals identical blocks within the ciphertext
          as demonstrated by the
          <a href="https://blog.filippo.io/the-ecb-penguin/">ECB penguin</a>,
          and CTR mode is often inappropriate because it does not
          perform authentication and causes duplicates if the input
          state is repeated).
        details: >
          In many cases it's best to choose a block cipher algorithm
          mode designed to combine secrecy and authentication, e.g.,
          Galois/Counter Mode (GCM) and EAX.
          Projects MAY allow users to enable broken mechanisms where
          necessary for compatibility, but then users know they're doing it.
        rationale: >
          If a cryptographic algorithm or mode is completely broken,
          then it cannot provide a useful cryptographic service.
          This is different from having a weakness;
          many cryptographic algorithms have some weaknesses, yet for
          backwards-compatibility it may sometimes be appropriate to use
          the algororithm anyway.
          "EAX" appears to be a name, not an abbrevation.
          The paper describing EAX,
          <a href="http://csrc.nist.gov/groups/ST/toolkit/BCM/documents/proposedmodes/eax/eax-spec.pdf">"A
          Conventional Authenticated-Encryption Mode" by
          M. Bellare, P.  Rogaway D.  Wagner (April 13, 2003)</a>,
          does not give an expansion.
        # autofill: TODO
    - crypto_weaknesses:
        category: SHOULD
        na_allowed: true
        description: >
          The default security mechanisms within the software produced
          by the project MUST NOT depend on
          cryptographic algorithms or modes with known serious weaknesses
          (e.g., the SHA-1 cryptographic hash algorithm or the CBC mode in SSH).
        details: >
          Concerns about CBC mode in SSH are discussed in
          <a href="https://www.kb.cert.org/vuls/id/958563">CERT:
          SSH CBC vulnerability</a>.
        rationale: >
          SHA-1 has been known to be weak for many years;
          <a href="https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html">In February 2017 Google demonstrated a SHA-1 collision</a>.
          There are a number of alternatives to SHA-1 that are not
          patent-encumbered, such as the
          SHA-2 suite (including SHA-256 and SHA-512) and SHA-3.
          There is some disagreement on how important it is to avoid
          CBC mode in SSH.  The
          <a href="http://www.openssh.com/txt/cbc.adv">OpenSSH cbc.adv</a>
          page argues that the attack on SSH CBC is not a practical attack.
          However, others clearly think it's more important; CERT notes it,
          as does
          <a href="https://developer.ibm.com/answers/questions/187318/faq-how-do-i-disable-cipher-block-chaining-cbc-mod.html">FAQ: Disable CBC in SSH</a>.
          It is also easy to use a different mode than CBC; generally
          when there are safer widely-available options, you should use
          the safe ones instead.
          This is a SHOULD, not a MUST; sometimes these weaker
          mechanisms need to be used for backwards compatibility.
        # autofill: TODO
    - crypto_pfs:
        category: SHOULD
        na_allowed: true
        description: >
          The security mechanisms within the software produced
          by the project SHOULD implement
          perfect forward secrecy for key agreement
          protocols so a session key derived from a set of long-term keys cannot
          be compromised if one of the long-term keys is compromised
          in the future.
        # autofill: TODO
    - crypto_password_storage:
        category: MUST
        na_allowed: true
        description: >
          If the software produced by the project causes the storing of
          passwords for authentication of external users, the passwords
          MUST be stored as iterated hashes with a per-user salt by
          using a key stretching (iterated) algorithm (e.g., PBKDF2, Bcrypt
          or Scrypt).
        rationale: >
          This is a bare minimum today when storing passwords.
          Sometimes software needs to have a credential, such as a password,
          to authenticate it to other systems; those are intentionally
          out of scope for this criterion, because in many cases it's not
          possible to store them as iterated hashes using per-user salt.
        # autofill: TODO
    - crypto_random:
        category: MUST
        na_allowed: true
        description: >
          The security mechanisms within the software produced
          by the project MUST generate all cryptographic keys and nonces
          using a cryptographically secure random number generator,
          and MUST NOT do so using generators that are
          cryptographically insecure.
        details: >
          A cryptographically secure random number generator may be a
          hardware random number generator, or it may be
          a cryptographically secure pseudo-random number generator (CSPRNG)
          using an algorithm such as Hash_DRBG, HMAC_DRBG, CTR_DRBG,
          Yarrow, or Fortuna.
          Examples of calls to <i>secure</i> random number generators include
          Java's java.security.SecureRandom and JavaScript's
          window.crypto.getRandomValues.
          Examples of calls to <i>insecure</i> random number generators include
          Java's java.util.Random and JavaScript's Math.random.
        # autofill: TODO
  - Secured delivery against man-in-the-middle (MITM) attacks: !!omap
    - delivery_mitm:
        category: MUST
        description: >
          The project MUST use a delivery mechanism that counters MITM attacks.
          Using https or ssh+scp is acceptable.
        details: >
          An even stronger mechanism is releasing the software with digitally
          signed packages, since that mitigates attacks on the distribution
          system, but this only works if the users can be confident that the
          public keys for signatures are correct <i>and</i> if the users will
          actually check the signature.
        autofill: >
          Look for a download site using https.
    - delivery_unsigned:
        category: MUST
        description: >
          A cryptographic hash (e.g., a sha1sum) MUST NOT be retrieved
          over http and used without checking for a cryptographic signature.
        details: >
          These hashes can be modified in transit.
        autofill: >
          Again, look for a download site using https.
  - Publicly known Vulnerabilities fixed: !!omap
    - vulnerabilities_fixed_60_days:
        category: MUST
        description: >
          There MUST be no unpatched vulnerabilities of medium or high severity that
          have been publicly known for more than 60 days.
        details: >
          The vulnerability must be patched and released by the project itself
          (patches may be developed elsewhere).  A vulnerability becomes
          publicly known (for this purpose) once it has a CVE with
          publicly released non-paywalled information (reported, for example,
          in the <a href="https://nvd.nist.gov/">National Vulnerability
          Database</a>) or when the project has been informed and the
          information has been released to the public (possibly by the project).
          A vulnerability is medium
          to high severity if its <a href="https://nvd.nist.gov/cvss.cfm">CVSS
          2.0</a> base score is 4 or higher.
          <b>Note</b>: this means that users might be left vulnerable to all
          attackers worldwide for up to 60 days.  This criterion is often
          much easier to meet than what Google recommends in <a
          href="https://security.googleblog.com/2010/07/rebooting-responsible-disclosure-focus.html">Rebooting
          responsible disclosure</a>, because Google recommends that the 60-day
          period start when the project is notified <em>even</em> if the report
          is not public.
        rationale: >
          We intentionally chose to start measurement from the
          time of public knowledge,
          and not from the time reported to the project, because this is much
          easier to measure and
          verify by those outside the project.
        autofill: >
          Look at vulnerability databases (such as NVD),
          pull out unpatched ones, and look at days since report.
    - vulnerabilities_critical_fixed:
        category: SHOULD
        description: >
          Projects SHOULD fix all critical vulnerabilities rapidly after they
          are reported.
        autofill: >
           Look at vulnerability databases for say the last 2 years, and
           find the worst-case time for response to any
           critical vulnerabilities.
           More than 60 days is not a good sign.
  - Other security issues: !!omap
    - no_leaked_credentials:
        category: MUST
        description: >
          The public repositories MUST NOT leak a valid private credential
          (e.g., a working password or private key) that is intended to limit
          public access.
        details: >
          A project MAY leak "sample" credentials for testing and
          unimportant databases, as long as they are not intended to limit
          public access.
        autofill: >
          Search repo for filenames that suggest credential leaking, e.g.,
          id_dsa (SSH private key).  Could also look at file contents for
          things like Amazon keys or Heroku keys.
          Could look at .env file, though "SECRETS" there might not really
          be secrets.
- Analysis: !!omap
  - Static code analysis: !!omap
    - static_analysis:
        category: MUST
        na_allowed: true
        na_justification_required: true
        description: >
          At least one static code analysis tool MUST be applied to any proposed
          major production release of the software before its release,
          if there is at least one FLOSS tool that implements this criterion in
          the selected language.
        details: >
          A static code analysis tool examines the software code (as source
          code, intermediate code, or executable) without executing it
          with specific inputs.  For purposes of this criterion, compiler
          warnings and "safe" language modes do not count as static code
          analysis tools (these typically avoid deep analysis because
          speed is vital).  Examples of such static code analysis tools
          include <a href="http://cppcheck.sourceforge.net/">cppcheck</a>,
          <a href="http://clang-analyzer.llvm.org/">clang static analyzer</a>,
          <a href="http://findbugs.sourceforge.net/">FindBugs</a> (including <a
          href="https://h3xstream.github.io/find-sec-bugs/">FindSecurityBugs</a>),
          <a href="https://pmd.github.io/">PMD</a>,
          <a href="http://brakemanscanner.org/">Brakeman</a>,
          <a href="https://scan.coverity.com/">Coverity Quality Analyzer</a>, and
          <a href="http://www8.hp.com/au/en/software-solutions/static-code-analysis-sast/index.html">HP
          Fortify Static Code Analyzer</a>.
          Larger lists of tools can be found in places such as the
          <a href="https://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis">Wikipedia
          list of tools for static code analysis</a>,
          <a href="https://www.owasp.org/index.php/Static_Code_Analysis">OWASP
          information on static code analysis</a>,
          <a href="http://samate.nist.gov/index.php/Source_Code_Security_Analyzers.html">NIST
          list of source code security analyzers</a>, and
          <a href="http://www.dwheeler.com/essays/static-analysis-tools.html">Wheeler's
          list of static analysis tools</a>.
          The <a href="https://continuousassurance.org/">SWAMP</a> is a no-cost
          platform for assessing vulnerabilities in software using a variety
          of tools.
          If there are no FLOSS static analysis tools available for
          the implementation language(s) used, select 'N/A'.
        na_placeholder: >
          Why can't this be met (e.g., no FLOSS tools exist for that language)?
        met_placeholder: >
          What static analysis tool(s) are used?
        autofill: >
          Look in build scripts for execution of common tools, and in
          documentation for names of tools and the URL of a Coverity scan entry.
    - static_analysis_common_vulnerabilities:
        category: SUGGESTED
        na_allowed: true
        description: >
          It is SUGGESTED that at least one of the static analysis tools
          used for the static_analysis criterion
          include rules or approaches to look for
          common vulnerabilities in the analyzed language or environment.
        autofill: >
          We might start by looking primarily for tools that also meet this.
          E.g., brakeman for Ruby on Rails.
    - static_analysis_fixed:
        category: MUST
        na_allowed: true
        description: >
          All medium and high severity exploitable vulnerabilities
          discovered with static code analysis MUST be fixed
          in a timely way after they are confirmed.
        details: >
          A vulnerability is medium to high severity if its <a
          href="https://nvd.nist.gov/cvss.cfm">CVSS 2.0</a> is 4 or higher.
        # autofill: TODO
    - static_analysis_often:
        category: SUGGESTED
        na_allowed: true
        description: >
          It is SUGGESTED that static source code analysis occur on every
          commit or at least daily.
        autofill: >
          Look for commit hooks or continuous integration tools like CircleCI
          that would meet this.
  - Dynamic code analysis: !!omap
    - dynamic_analysis:
        category: SUGGESTED
        description: >
          It is SUGGESTED that at least one dynamic analysis tool be applied
          to any proposed major production release of the software before
          its release.
        details: >
          A dynamic analysis tool examines the software
          by executing it with specific inputs.
          For example, the project MAY use a fuzzing tool (e.g.,
          <a href="http://lcamtuf.coredump.cx/afl/">American
          Fuzzy Lop</a>) or a web application scanner (e.g.,
          <a href="https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project">OWASP
          ZAP</a> or <a href="http://w3af.org/">w3af</a>).
          In some cases the
          <a href="https://github.com/google/oss-fuzz#introduction">OSS-Fuzz</a>
          project may be willing to apply fuzz testing to your project.
          For purposes of this criterion the dynamic analysis
          tool needs to vary the inputs in some way to look for
          various kinds of problems <em>or</em> be an automated
          test suite with at least 80% branch coverage.  The
          <a href="https://en.wikipedia.org/wiki/Dynamic_program_analysis">Wikipedia
          page on dynamic analysis</a> and the
          <a href="https://www.owasp.org/index.php/Fuzzing">OWASP page on
          fuzzing</a> identify some dynamic analysis tools.
          The analysis tool(s) MAY be focused on looking for security
          vulnerabilities, but this is not required.
        rationale: >
          Static source code analysis and dynamic analysis tend
          to find different kinds of defects (including defects that lead to
          vulnerabilities), so combining them is more likely to be effective.
        autofill: >
          Look in documentation for references to such tools.
    - dynamic_analysis_unsafe:
        category: SUGGESTED
        na_allowed: true
        description: >
          It is SUGGESTED that if the project results include
          software written using a memory-unsafe language (e.g., C or C++),
          then at least one dynamic tool (e.g., a fuzzer or web
          application scanner) be routinely used in combination with
          a mechanism to detect memory safety problems such as buffer
          overwrites.
          If the project results do not include software written
          in a memory-unsafe language, choose "not applicable" (N/A).
        details: >
          Examples of mechanisms to detect memory safety problems include
          <a href="https://github.com/google/sanitizers/wiki/AddressSanitizer">Address Sanitizer (ASAN)</a>
          (available in GCC and LLVM),
          <a href="http://clang.llvm.org/docs/MemorySanitizer.html">Memory Sanitizer</a>,
          and <a href="http://valgrind.org/">valgrind</a>.
          Other potentially-used tools include
          <a href="http://clang.llvm.org/docs/ThreadSanitizer.html">thread sanitizer</a>
          and
          <a href="http://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html">undefined behavior sanitizer</a>.
          Widespread assertions would also work.
        autofill: >
          Look in build/test script for reference to invocation of
          valgrind or ASAN.
    - dynamic_analysis_enable_assertions:
        category: SUGGESTED
        description: >
          It is SUGGESTED that the software include many run-time assertions
          that are checked during dynamic analysis.
        autofill: >
          Perhaps look in source code for many asserts.
    - dynamic_analysis_fixed:
        category: MUST
        na_allowed: true
        description: >
          All medium and high severity exploitable vulnerabilities
          discovered with dynamic code analysis MUST be fixed
          in a timely way after they are confirmed.
        details: >
           A vulnerability is medium to high severity if its <a
           href="https://nvd.nist.gov/cvss.cfm">CVSS 2.0</a> base score is 4.
           If you are not running dynamic code analysis and thus have not
           found any vulnerabilities in this way, choose "not applicable" (N/A).
        # autofill: TODO
- Future: !!omap
  - future: !!omap
    - installation_common: # Put after 'english'
        category: SHOULD
        future: true
        description: >
          The project SHOULD
          provide a way to easily install and uninstall the software using a
          commonly-used convention.
        details: >
          Examples include using a package manager (at
          the system or language level), "make install/uninstall" (supporting
          DESTDIR), a container in a standard format,
          or a virtual machine image in a standard format.
          The installation and uninstallation process (e.g., its packaging)
          MAY be implemented by a third party as long as it is FLOSS.
        autofill: >
          Look for a standard install format, or a build instruction for one.
    - build_reproducible: # After build_floss_tools
        category: SUGGESTED
        future: true
        na_allowed: true
        description: >
          It is SUGGESTED that
          the project have a
          <a href="https://reproducible-builds.org/">reproducible build</a>.
        details: >
          A reproducible build means that multiple parties can
          independently redo the process of generating information from
          source files and get exactly the same bit-for-bit result.  If no
          building occurs (e.g., scripting languages where the source
          code is used directly instead of being compiled), select "N/A".
          In some cases, this can resolved by forcing some sort order.
          JavaScript developers may consider using npm shrinkwrap and
          webpack OccurenceOrderPlugin.  GCC and clang users may find
          the -frandom-seed option useful.  The build environment
          (including the toolset) can often be defined for external
          parties by specifying the cryptographic hash of a specific
          container or virtual machine that they can use for rebuilding.
          The <a href="https://reproducible-builds.org/docs/">reproducible
          builds project has documentation on how to do this</a>.
        rationale: >
          If a project needs to be built but there is no working
          build system, then potential co-developers will not be able to easily
          contribute and many security analysis tools will be ineffective.
          Reproduceable builds counter malicious attacks that generate malicious
          executables, by making it easy to recreate the executable to determine
          if the result is correct.
          By itself, reproducible builds do not counter malicious compilers,
          but they can be extended to counter malicious compilers using
          processes such as diverse double-compiling (DDC).
        autofill: >
          If the project seems to only have scripting language code,
          prefill it as N/A.
          Otherwise, check if the reproducible build project lists the project
          as being reproducible.
          The only *real* way to check is to actually perform the build
          multiple times, but we don't have time for that.
    - crypto_used_network:
        category: SHOULD
        future: true
        na_allowed: true
        description: >
          The project SHOULD NOT use
          unencrypted network communication protocols (such as HTTP and telnet)
          if there an encrypted equivalent (e.g., HTTPS/TLS and SSH),
          unless the user specifically requests or configures it.
    - crypto_tls12:
        category: SHOULD
        future: true
        na_allowed: true
        description: >
          The project SHOULD,
          if it supports TLS, support at least TLS version 1.2.
          Note that the predecessor of TLS was called SSL.
    - crypto_certificate_verification:
        category: MUST
        future: true
        na_allowed: true
        description: >
          The project MUST,
          if it supports TLS, perform TLS certificate verification by default
          when using TLS, including on subresources.
        details: >
          Note that incorrect TLS certificate verification is a common mistake.
          For more information, see
          <a href="http://crypto.stanford.edu/~dabo/pubs/abstracts/ssl-client-bugs.html">"The Most Dangerous Code in the World: Validating SSL Certificates in Non-Browser Software" by Martin Georgiev et al.</a>
          and
          <a href="https://blogs.gnome.org/mcatanzaro/2016/03/12/do-you-trust-this-application/">"Do you trust this application?" by Michael Catanzaro</a>.
    - crypto_verification_private:
        category: SHOULD
        future: true
        na_allowed: true
        description: >
          The project SHOULD,
          if it supports TLS, perform certificate verification
          before sending HTTP headers with private information
          (such as secure cookies).
    - hardened_site: # After delivery_mitm?
        category: SUGGESTED
        future: true
        description: >
          It is SUGGESTED that the project website, repository (if accessible
          via the web), and download site (if separate) include key hardening
          headers with nonpermissive values.
        details: >
          Note that GitHub is known to meet this.
          Sites such as https://securityheaders.io/ can quickly check this.
          The key hardening headers are:
          Content Security Policy (CSP), HTTP Strict Transport Security
          (HSTS), X-Content-Type-Options (as "nosniff"), X-Frame-Options,
          and X-XSS-Protection.
        autofill: >
          Load the URLs and look for those HTTP headers. In the future, we
          may want to specify certain disallowed content security policies.
          See http://content-security-policy.com/.
    - hardening: # In 'Other security issues'
        category: SUGGESTED
        future: true
        description: >
          It is SUGGESTED that hardening mechanisms be used so software defects
          are less likely to result in security vulnerabilities.
        details: >
          Hardening mechanisms may include
          HTTP headers like Content Security Policy (CSP),
          compiler flags to mitigate attacks
          (such as -fstack-protector), or compiler flags to
          eliminate undefined behavior.
          For our purposes least privilege is not considered a hardening
          mechanism (least privilege is important, but separate).
        autofill: >
          Look for gems like secure_headers, and
          relevant compiler flags in build files.
